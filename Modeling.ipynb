{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occupational-beauty",
   "metadata": {},
   "source": [
    "# Module and Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "natural-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-party",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "southeast-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-rubber",
   "metadata": {},
   "source": [
    "## Modeling Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noble-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils import resample\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-arrest",
   "metadata": {},
   "source": [
    "# Load our Xs and Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proprietary-nursing",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a717e9c0b49a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X_train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X_test\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_trian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y_train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y_test\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = pickle.load(open(\"X_train\", 'rb'))\n",
    "X_test = pickle.load(open(\"X_test\", 'rb'))\n",
    "y_trian = pickle.load(open(\"y_train\", 'rb'))\n",
    "y_test = pickl.load(open(\"y_test\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-accommodation",
   "metadata": {},
   "source": [
    "### Helper Funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "close-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_buddy(model_to_fit, dictionary_string, dicto):\n",
    "    funky_time_start = time.time()\n",
    "    model_to_fit.fit(X_train, np.ravel(y_train))\n",
    "    funky_time_stop = time.time()\n",
    "    funky_train_time = funky_time_stop - funky_time_start\n",
    "    dicto[dictionary_string]['training_time'] = funky_train_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "standing-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confused_buddy(model_to_confuse, dictionary_string,dicto):\n",
    "    confuse = confusion_matrix(y_test, model_to_confuse.predict(X_test))\n",
    "    dicto[dictionary_string]['confuse'] = confuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "preceding-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_calculator(confuse):\n",
    "    recall = 0\n",
    "    tp = confuse[1][1]\n",
    "    fn = confuse[1][0]\n",
    "    if tp > 0 or tp ==1:\n",
    "        recall = tp / (tp+fn)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "vocational-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_calculator(confuse):\n",
    "    precision = 0\n",
    "    print(confuse)\n",
    "    tp = confuse[1][1]\n",
    "    fp = confuse[0][1]\n",
    "    if tp > 0 or tp ==1:\n",
    "        precision = tp / (tp+fp)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-cherry",
   "metadata": {},
   "source": [
    "## Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "harmful-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classy_dummy(dicto, X_train, y_train, X_test, y_test):\n",
    "    print('dumbo')\n",
    "    dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "    timing_buddy(dummy_clf, 'dummy', dicto)\n",
    "    confused_buddy(dummy_clf, 'dummy', dicto)\n",
    "    confused_buddy(dummy_clf, 'dummy', dicto)\n",
    "    dicto['dummy']['ROC_AUC_Score'] = roc_auc_score(y_test, dummy_clf.predict_proba(X_test)[:, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-extension",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "opposed-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVCmodeler(dicto, X_train, y_train, X_test, y_test):\n",
    "    print('Support Vector Classification')\n",
    "    SupportVectorClassifier = SVC()\n",
    "    timing_buddy(SupportVectorClassifier, 'SVC', dicto)\n",
    "    confused_buddy(SupportVectorClassifier, 'SVC', dicto)\n",
    "    dicto['SVC']['ROC_AUC_Score'] = roc_auc_score(y_test, SupportVectorClassifier.decision_function(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-freeze",
   "metadata": {},
   "source": [
    "## Stochastic Gradiant Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "matched-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_sgd_model(dicto, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    def SGDHyperParameterer(loss_penalty_list):\n",
    "        SGD_clf = SGDClassifier(loss = loss_penalty_list[0], penalty=loss_penalty_list[1])\n",
    "        SGD_clf.fit(X_train, np.ravel(y_train))\n",
    "        confuse = confusion_matrix(y_test, SGD_clf.predict(X_test))\n",
    "        recall = recall_calculator(confuse)\n",
    "        return recall\n",
    "    \n",
    "    \n",
    "    losses= ['modified_huber', 'log']\n",
    "    penalties = ['l2', 'l1', 'elasticnet']\n",
    "    param_grid = {}\n",
    "    count = 0\n",
    "    for each_loss in losses:\n",
    "        for each_penalty in penalties:\n",
    "            param_grid[str(each_loss) + '-' + str(each_penalty)] = [each_loss, each_penalty]\n",
    "            count+=1\n",
    "\n",
    "    \n",
    "    ###\n",
    "    SGD_Hyper_param_recall_scores = {}\n",
    "    for key, value in param_grid.items():\n",
    "        SGD_Hyper_param_recall_scores[key] = SGDHyperParameterer(value)\n",
    "\n",
    "    ###\n",
    "    \n",
    "    print('Stochastic Gradiant Descent')\n",
    "    best_recall = 0\n",
    "    penalty = ''\n",
    "    loss = ''\n",
    "    for key, value in SGD_Hyper_param_recall_scores.items():\n",
    "        if value > best_recall:\n",
    "            best_recall = value\n",
    "            loss, penalty = key.split('-')\n",
    "            \n",
    "        \n",
    "                                                                 \n",
    "    \n",
    "    ###\n",
    "    SGD_clf = SGDClassifier(loss = loss, penalty= penalty)\n",
    "    timing_buddy(SGD_clf, 'SGDClassfier', dicto)\n",
    "    confused_buddy(SGD_clf, 'SGDClassfier', dicto)\n",
    "    dicto['SGDClassfier']['ROC_AUC_Score'] = roc_auc_score(y_test, SGD_clf.decision_function(X_test))\n",
    "    dicto['SGDClassfier']['Hyper_Params'] = {'Loss': loss, 'penalty':penalty}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-vampire",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "virgin-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_rf_model(dicto, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    def bayes_RFModeler_sqrt(n_estimators, \n",
    "                             max_depth,\n",
    "                             min_samples_split,\n",
    "                             min_samples_leaf):\n",
    "        RandoForest = RandomForestClassifier(n_estimators=int(n_estimators), max_features='sqrt', max_depth=int(max_depth),\n",
    "                                             min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf))\n",
    "        RandoForest.fit(X_train, np.ravel(y_train))\n",
    "        confuse = confusion_matrix(y_test, RandoForest.predict(X_test))\n",
    "        recall = recall_calculator(confuse)\n",
    "        return recall\n",
    "\n",
    "    \n",
    "    ###\n",
    "    param_dicts = { 'n_estimators' : (100, 2000),\n",
    "              'max_depth' : (10,60),\n",
    "              'min_samples_split': (2,10),\n",
    "              'min_samples_leaf' : (1,5),\n",
    "              }\n",
    "    ###\n",
    "    \n",
    "    optimizer = BayesianOptimization(\n",
    "    bayes_RFModeler_sqrt,\n",
    "    pbounds=param_dicts,\n",
    "    verbose=1)\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    print('Random Forest')\n",
    "    optimizer.maximize(init_points=15, n_iter=10)\n",
    "    rf_params= optimizer.max\n",
    "    rf_params = rf_params['params']\n",
    "    \n",
    "    ###\n",
    "    RandoForest = RandomForestClassifier(n_estimators=int(rf_params['n_estimators']), \n",
    "                                         max_features='sqrt',\n",
    "                                         max_depth=int(rf_params['max_depth']),\n",
    "                                         min_samples_split=int(rf_params['min_samples_split']),\n",
    "                                         min_samples_leaf=int(rf_params['min_samples_leaf']))\n",
    "    \n",
    "    timing_buddy(RandoForest, 'RandomForestClassifier', dicto)\n",
    "    confused_buddy(RandoForest, 'RandomForestClassifier', dicto)\n",
    "    dicto['RandomForestClassifier']['ROC_AUC_Score'] = roc_auc_score(y_test, RandoForest.predict_proba(X_test)[:, 1])\n",
    "    dicto['RandomForestClassifier']['Hyper_Params'] = rf_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-performer",
   "metadata": {},
   "source": [
    "## AdaBooast Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "based-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_hyper_ada_boost_model(dicto, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    def AdaBoost_hyper(n_estimators, learning_rate):\n",
    "        adaira_the_classifier = AdaBoostClassifier(learning_rate=learning_rate,  n_estimators=int(n_estimators))\n",
    "        adaira_the_classifier.fit(X_train, np.ravel(y_train))\n",
    "        confuse = confusion_matrix(y_test, adaira_the_classifier.predict(X_test))\n",
    "        recall = recall_calculator(confuse)\n",
    "        return recall\n",
    "\n",
    "    \n",
    "    ###\n",
    "    ada_params = {'learning_rate' : (.1,2),\n",
    "              'n_estimators':(10,500),}\n",
    "    ###\n",
    "    \n",
    "    optimizer = BayesianOptimization(\n",
    "    AdaBoost_hyper,\n",
    "    pbounds=ada_params,\n",
    "    verbose=1)\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    print('AdaBoost')\n",
    "    optimizer.maximize(init_points=15, n_iter=10)\n",
    "    ada_boost_params= optimizer.max\n",
    "    ada_boost_params = ada_boost_params['params']\n",
    "    \n",
    "    ###\n",
    "    adaira_the_classifier = AdaBoostClassifier(learning_rate=ada_boost_params['learning_rate'],  n_estimators=int(ada_boost_params['n_estimators']))\n",
    "    timing_buddy(adaira_the_classifier, 'AdaBoostClassifier', dicto)\n",
    "    confused_buddy(adaira_the_classifier, 'AdaBoostClassifier', dicto)\n",
    "    dicto['AdaBoostClassifier']['ROC_AUC_Score'] = roc_auc_score(y_test, adaira_the_classifier.predict_proba(X_test)[:, 1])\n",
    "    dicto['AdaBoostClassifier']['Hyper_Params'] = ada_boost_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-short",
   "metadata": {},
   "source": [
    "## Gradiant Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cheap-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_hyper_grad_boosting_model(dicto, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    def GradBoost_hyper(n_estimators, learning_rate, max_leaf_nodes):\n",
    "        grady_the_boosted = GradientBoostingClassifier(learning_rate=learning_rate,  n_estimators=int(n_estimators),\n",
    "                                                      max_leaf_nodes=int(max_leaf_nodes))\n",
    "        grady_the_boosted.fit(X_train, np.ravel(y_train))\n",
    "        confuse = confusion_matrix(y_test, grady_the_boosted.predict(X_test))\n",
    "        recall = recall_calculator(confuse)\n",
    "        return recall\n",
    "    \n",
    "    ###\n",
    "    GradBoost_params = {'learning_rate' : (.1,2),\n",
    "                    'n_estimators':(10,500),\n",
    "                    'max_leaf_nodes':(3,50)}\n",
    "    ###\n",
    "    \n",
    "    optimizer = BayesianOptimization(\n",
    "    GradBoost_hyper,\n",
    "    pbounds=GradBoost_params,\n",
    "    verbose=1)\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    print('Gradient Boosting')\n",
    "    optimizer.maximize(init_points=15, n_iter=10)\n",
    "    grad_boost_params= optimizer.max\n",
    "    grad_boost_params = grad_boost_params['params']\n",
    "    \n",
    "    ###\n",
    "    grady_the_boosted = GradientBoostingClassifier(learning_rate=grad_boost_params['learning_rate'],\n",
    "                                                   n_estimators=int(grad_boost_params['n_estimators']),\n",
    "                                                   max_leaf_nodes=int(grad_boost_params['max_leaf_nodes']))\n",
    "    timing_buddy(grady_the_boosted, 'GradientBoostingClassifier', dicto)\n",
    "    confused_buddy(grady_the_boosted, 'GradientBoostingClassifier', dicto)\n",
    "    dicto['GradientBoostingClassifier']['ROC_AUC_Score'] = roc_auc_score(y_test, grady_the_boosted.predict_proba(X_test)[:, 1])\n",
    "    dicto['GradientBoostingClassifier']['Hyper_Params'] = grad_boost_params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-nashville",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-procurement",
   "metadata": {},
   "source": [
    "#precision = tp/(tp+fp)\n",
    "maximize this for spam, don't wanna be hiding real emails\n",
    "\n",
    "#recall= tp/(tp+fn) \n",
    "Maximize this for medical or security scenarios, don't wanna miss actual sicknesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "compact-given",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def medical_evaluator(dicto):\n",
    "    bestmodel = \"\"\n",
    "    training_time= 0\n",
    "    recall = 0\n",
    "    temp_recall = 0\n",
    "    for key, value in dicto.items():\n",
    "        \n",
    "        confuse = dicto[key]['confuse']\n",
    "        if type(confuse) != list:\n",
    "            temp_recall = recall_calculator(confuse)\n",
    "\n",
    "            if temp_recall > recall:\n",
    "\n",
    "                recall = temp_recall\n",
    "                bestmodel = key\n",
    "                training_time = dicto[key]['training_time']\n",
    "    return bestmodel, recall, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "expired-danger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def spam_evaluator(dicto):\n",
    "    bestmodel = \"\"\n",
    "    training_time= 0\n",
    "    precision = 0\n",
    "    temp_precision = 0.00000001\n",
    "    for key, value in dicto.items():\n",
    "        confuse = dicto[key]['confuse']\n",
    "        if type(confuse) != list:\n",
    "            temp_precision = precision_calculator(confuse)\n",
    "\n",
    "            if temp_precision > precision:\n",
    "\n",
    "                precision = temp_precision\n",
    "                bestmodel = key\n",
    "                training_time = dicto[key]['training_time']\n",
    "    return bestmodel, precision, training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-cambridge",
   "metadata": {},
   "source": [
    "# Model Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-banks",
   "metadata": {},
   "source": [
    "### Aggregate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "inside-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chonky_model_aggregator(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    #Models to explore\n",
    "    model_set = ['dummy','SVC', 'SGDClassfier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier']\n",
    "    model_stats = {}\n",
    "    for each in model_set:\n",
    "        model_stats[each] ={'confuse' : [], 'training_time' : 0, 'ROC_AUC_Score': 0, 'Hyper_Params': {}}\n",
    "    #model running\n",
    "    classy_dummy(model_stats, X_train, y_train, X_test, y_test)\n",
    "    SVCmodeler(model_stats, X_train, y_train, X_test, y_test)\n",
    "    grid_sgd_model(model_stats, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    bayes_rf_model(model_stats, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    bayes_hyper_ada_boost_model(model_stats, X_train, y_train, X_test, y_test)\n",
    "    bayes_hyper_grad_boosting_model(model_stats, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "\n",
    "    return model_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-singing",
   "metadata": {},
   "source": [
    "### Stats Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-smart",
   "metadata": {},
   "source": [
    "#### Wide Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-clerk",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumbo\n",
      "Support Vector Classification\n",
      "Stochastic Gradiant Descent\n",
      "Random Forest\n",
      "|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9884  \u001b[0m | \u001b[95m 35.27   \u001b[0m | \u001b[95m 2.904   \u001b[0m | \u001b[95m 7.434   \u001b[0m | \u001b[95m 1.924e+0\u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.9942  \u001b[0m | \u001b[95m 16.01   \u001b[0m | \u001b[95m 1.762   \u001b[0m | \u001b[95m 9.17    \u001b[0m | \u001b[95m 460.6   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9973  \u001b[0m | \u001b[95m 13.43   \u001b[0m | \u001b[95m 2.999   \u001b[0m | \u001b[95m 8.623   \u001b[0m | \u001b[95m 903.2   \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "wide_data_model_stats = chonky_model_aggregator(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-chart",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wide_data_model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(wide_data_model_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-picture",
   "metadata": {},
   "source": [
    "### Stats Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-enough",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(medical_evaluator(wide_data_model_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-dining",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_dict= {}\n",
    "for key, value in wide_data_model_stats.items():\n",
    "    time_dict[key] = value['training_time']\n",
    "    time_list = value['training_time']\n",
    "\n",
    "time_frame = pd.Series(time_dict)\n",
    "time_frame.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "confuse_dict= {}\n",
    "for key, value in wide_data_model_stats.items():\n",
    "    confuse_dict[key] = value['confuse']\n",
    "\n",
    "confuse_frame = pd.Series(confuse_dict)\n",
    "\n",
    "precision_dict= {}\n",
    "recall_dict = {}\n",
    "for i in confuse_frame.index:\n",
    "    precision_dict[i] = precision_calculator(confuse_frame[i])        \n",
    "    recall_dict[i] = recall_calculator(confuse_frame[i])        \n",
    "\n",
    "precision_frame = pd.Series(precision_dict)\n",
    "\n",
    "\n",
    "recall_frame = pd.Series(recall_dict)\n",
    "\n",
    "recall_frame = dict(recall_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_list = (recall_frame, precision_frame, time_frame)\n",
    "list_of_three = pd.DataFrame(data=working_list, index=['Recall','Precision','Time_To_Train'])\n",
    "list_of_three= list_of_three.transpose()\n",
    "list_of_three.loc['GradientBoostingClassifier'] #recall\n",
    "list_of_three.loc['SVC'] #precision\n",
    "list_of_three.loc['SGDClassfier'] #time\n",
    "#list_of_three.sort_values('Precision', ascending=False)\n",
    "list_of_three.sort_values('Time_To_Train')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-dancing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_med_model, med_recall, med_time = medical_evaluator(wide_data_model_stats)\n",
    "best_spam_model, spam_precision, spam_time = spam_evaluator(wide_data_model_stats)\n",
    "print(\"The best medical model (Optimizing for recall) is \" + best_med_model + \" It's recall score was\" + str(round(med_recall,3)) + \" and it took \" + str(round(med_time,2)) +\" seconds to run.\")\n",
    "print(\"\")\n",
    "print(\"The best spam model (Optimizing for precision) is \" + best_spam_model +\n",
    "      \" It's precision score was\" +str(round(spam_precision, 3)) +\" and it took \" + str(round(spam_time, 2) ) +\" seconds to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-channels",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, value in wide_data_model_stats.items():\n",
    "    if value['training_time'] !=0:\n",
    "        print(key)\n",
    "        print('')\n",
    "        for key2, value2 in value.items():\n",
    "            print(key2)\n",
    "            if key2 == 'confuse':\n",
    "                if type(value2) != list:\n",
    "                    print('recall: ' + str(round(recall_calculator(value2),2)))\n",
    "                    print('precision: ' +str(round(precision_calculator(value2),2)))\n",
    "            print(value2)\n",
    "            print('')\n",
    "        print('')\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save this iteration.\n",
    "\n",
    "pickle.dump( wide_data_model_stats, open( \"model_stats_02122022.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickles = ['model_stats_01012022.p','model_stats_01022022.p', 'model_stats_01032022.p', 'model_stats_01222022.p', \"model_stats_01242022.p\", \"model_stats_01252022.p\", \"model_stats_01262022.p\", \"model_stats_02122022.p\"]\n",
    "unpickles = []\n",
    "for each in pickles:\n",
    "    file = open(each, 'rb')\n",
    "    unpickles.append(pickle.load(file))\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in unpickles:\n",
    "    best_spam_model, spam_precision, spam_time = spam_evaluator(each)\n",
    "    print(best_spam_model, round(spam_precision,2), round(spam_time,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
